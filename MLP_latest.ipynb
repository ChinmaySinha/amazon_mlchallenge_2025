{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f0b5d9eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0b5d9eb",
        "outputId": "8799c25e-690d-40df-ba70-2f5e671e187e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete. Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# --- Core Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "\n",
        "# --- Machine Learning ---\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- Deep Learning (for Embeddings) ---\n",
        "import torch\n",
        "import timm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- Setup ---\n",
        "# Set up the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tqdm.pandas()\n",
        "\n",
        "print(f\"Setup complete. Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fc4d45d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc4d45d0",
        "outputId": "9fc7e114-86e3-46d9-a8b3-7a02bba5dc9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training Data ---\n",
            "Shape: (75000, 4)\n",
            "   sample_id                                    catalog_content  \\\n",
            "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
            "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
            "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
            "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
            "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
            "\n",
            "                                          image_link  price  \n",
            "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  \n",
            "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  \n",
            "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  \n",
            "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  \n",
            "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  \n",
            "\n",
            "--- Test Data ---\n",
            "Shape: (75000, 3)\n",
            "   sample_id                                    catalog_content  \\\n",
            "0     100179  Item Name: Rani 14-Spice Eshamaya's Mango Chut...   \n",
            "1     245611  Item Name: Natural MILK TEA Flavoring extract ...   \n",
            "2     146263  Item Name: Honey Filled Hard Candy - Bulk Pack...   \n",
            "3      95658  Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...   \n",
            "4      36806  Item Name: McCormick Culinary Vanilla Extract,...   \n",
            "\n",
            "                                          image_link  \n",
            "0  https://m.media-amazon.com/images/I/71hoAn78AW...  \n",
            "1  https://m.media-amazon.com/images/I/61ex8NHCIj...  \n",
            "2  https://m.media-amazon.com/images/I/61KCM61J8e...  \n",
            "3  https://m.media-amazon.com/images/I/51Ex6uOH7y...  \n",
            "4  https://m.media-amazon.com/images/I/71QYlrOMoS...  \n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "try:\n",
        "    train_df = pd.read_csv('dataset/train.csv')\n",
        "    test_df = pd.read_csv('dataset/test.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Please make sure train.csv and test.csv are in a 'dataset' folder.\")\n",
        "    # Create dummy dataframes to allow the rest of the notebook to run for demonstration\n",
        "    train_df = pd.DataFrame() \n",
        "    test_df = pd.DataFrame()\n",
        "\n",
        "print(\"--- Training Data ---\")\n",
        "print(f\"Shape: {train_df.shape}\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\n--- Test Data ---\")\n",
        "print(f\"Shape: {test_df.shape}\")\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f2317026",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2317026",
        "outputId": "c53e9904-6cb9-4622-c104-4d30834d1219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing catalog_content for train and test sets...\n",
            "Parsing complete.\n",
            "Encoding the 'Unit' feature...\n",
            "Encoding complete.\n",
            "\n",
            "--- Training Data After Parsing ---\n",
            "   sample_id  Pack_Size  Value   Unit  Unit_Encoded\n",
            "0      33127          6  72.00     Fl            20\n",
            "1     198967          4  32.00  Ounce            40\n",
            "2     261251          6  11.40  Ounce            40\n",
            "3      55858          1  11.25  Ounce            40\n",
            "4     292686          1  12.00  Count            16\n",
            "\n",
            "--- Test Data After Parsing ---\n",
            "   sample_id  Pack_Size  Value   Unit  Unit_Encoded\n",
            "0     100179          1   10.5  Ounce            40\n",
            "1     245611          1    2.0     Fl            20\n",
            "2     146263          1   32.0  Ounce            40\n",
            "3      95658          2    2.0  Count            16\n",
            "4      36806          1   32.0     Fl            20\n"
          ]
        }
      ],
      "source": [
        "def parse_catalog_content(text):\n",
        "    # Pack Size: Look for (Pack of X)\n",
        "    pack_size_match = re.search(r'\\(Pack of (\\d+)\\)', text, re.IGNORECASE)\n",
        "    pack_size = int(pack_size_match.group(1)) if pack_size_match else 1\n",
        "\n",
        "    # Value: Look for Value: X\n",
        "    value_match = re.search(r'Value: ([\\d.]+)', text)\n",
        "    value = float(value_match.group(1)) if value_match else np.nan\n",
        "\n",
        "    # Unit: Look for Unit: X (specifically letters to avoid capturing numbers)\n",
        "    unit_match = re.search(r'Unit: ([a-zA-Z]+)', text) # Corrected Regex\n",
        "    unit = unit_match.group(1) if unit_match else 'Unknown'\n",
        "\n",
        "    return pack_size, value, unit\n",
        "\n",
        "# Apply the parsing function to both dataframes\n",
        "print(\"Parsing catalog_content for train and test sets...\")\n",
        "train_df[['Pack_Size', 'Value', 'Unit']] = train_df['catalog_content'].apply(\n",
        "    lambda x: pd.Series(parse_catalog_content(x))\n",
        ")\n",
        "test_df[['Pack_Size', 'Value', 'Unit']] = test_df['catalog_content'].apply(\n",
        "    lambda x: pd.Series(parse_catalog_content(x))\n",
        ")\n",
        "print(\"Parsing complete.\")\n",
        "\n",
        "# --- FIX: Fit the encoder on ALL possible units ---\n",
        "print(\"Encoding the 'Unit' feature...\")\n",
        "# Combine units from both train and test sets to learn all possible labels\n",
        "all_units = pd.concat([train_df['Unit'], test_df['Unit']]).astype(str).unique()\n",
        "\n",
        "unit_encoder = LabelEncoder()\n",
        "unit_encoder.fit(all_units) # Fit on all unique units\n",
        "\n",
        "# Now transform train and test sets\n",
        "train_df['Unit_Encoded'] = unit_encoder.transform(train_df['Unit'].astype(str))\n",
        "test_df['Unit_Encoded'] = unit_encoder.transform(test_df['Unit'].astype(str))\n",
        "print(\"Encoding complete.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Training Data After Parsing ---\")\n",
        "print(train_df[['sample_id', 'Pack_Size', 'Value', 'Unit', 'Unit_Encoded']].head())\n",
        "\n",
        "print(\"\\n--- Test Data After Parsing ---\")\n",
        "print(test_df[['sample_id', 'Pack_Size', 'Value', 'Unit', 'Unit_Encoded']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7e12619e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Created Log-Transformed Features ---\n",
            "   Pack_Size  Pack_Size_log  Value  Value_log\n",
            "0          6       1.945910  72.00   4.290459\n",
            "1          4       1.609438  32.00   3.496508\n",
            "2          6       1.945910  11.40   2.517696\n",
            "3          1       0.693147  11.25   2.505526\n",
            "4          1       0.693147  12.00   2.564949\n"
          ]
        }
      ],
      "source": [
        "# Cell 3b: Create Log-Transformed Numerical Features\n",
        "\n",
        "# Apply log transform to skewed numerical features to help the model\n",
        "# We use log1p which handles zeros safely (log(1+x))\n",
        "for col in ['Pack_Size', 'Value']:\n",
        "    train_df[f'{col}_log'] = np.log1p(train_df[col])\n",
        "    test_df[f'{col}_log'] = np.log1p(test_df[col])\n",
        "\n",
        "print(\"--- Created Log-Transformed Features ---\")\n",
        "print(train_df[['Pack_Size', 'Pack_Size_log', 'Value', 'Value_log']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d2306e18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating clean text column...\n",
            "--- Sample Cleaned Text ---\n",
            "La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6) Oz\n"
          ]
        }
      ],
      "source": [
        "# Cell 3c: Create a Clean Text Column for Embeddings\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove boilerplate patterns\n",
        "    text = re.sub(r'Item Name:', '', text)\n",
        "    text = re.sub(r'Bullet Point \\d+:', '', text)\n",
        "    text = re.sub(r'Value: [\\d.]+', '', text)\n",
        "    text = re.sub(r'Unit: \\w+', '', text)\n",
        "    text = re.sub(r'Product Description:', '', text)\n",
        "    # Remove extra whitespace and newlines\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "print(\"Creating clean text column...\")\n",
        "train_df['clean_catalog_content'] = train_df['catalog_content'].apply(clean_text)\n",
        "test_df['clean_catalog_content'] = test_df['catalog_content'].apply(clean_text)\n",
        "\n",
        "print(\"--- Sample Cleaned Text ---\")\n",
        "print(train_df['clean_catalog_content'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e6f245f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting brand names...\n",
            "Brand feature created.\n",
            "Creating interaction and text statistic features...\n",
            "Additional features created.\n",
            "\n",
            "--- Sample of New Features ---\n",
            "     brand  brand_encoded  item_size  desc_length\n",
            "0       LA           6746  11.999998           58\n",
            "1  SALERNO          10361   7.999998          395\n",
            "2     BEAR           1351   1.900000          212\n",
            "3  JUDEE’S           6241  11.249989         1180\n",
            "4    KEDEM           6389  11.999988          119\n"
          ]
        }
      ],
      "source": [
        "# Cell 3d: Advanced Feature Engineering (Brand, Item Size, Text Length) - CORRECTED\n",
        "\n",
        "# --- 1. Extract Brand Name (with robust error handling) ---\n",
        "\n",
        "def extract_brand(item_name):\n",
        "    \"\"\"Extracts the first word of an item name as the brand.\"\"\"\n",
        "    try:\n",
        "        brand = item_name.split()[0].upper()\n",
        "        return brand\n",
        "    except (IndexError, AttributeError):\n",
        "        # Handles empty or invalid item_name strings\n",
        "        return 'UNKNOWN'\n",
        "\n",
        "def get_brand_from_catalog(catalog_text):\n",
        "    \"\"\"Safely finds the 'Item Name' section and extracts the brand.\"\"\"\n",
        "    # THIS IS THE FIX: Check if 'Item Name:' exists first\n",
        "    if 'Item Name:' in catalog_text:\n",
        "        # If it exists, proceed with the original logic\n",
        "        item_name_section = catalog_text.split('Item Name:')[1]\n",
        "        item_name = item_name_section.split('\\n')[0].strip()\n",
        "        return extract_brand(item_name)\n",
        "    else:\n",
        "        # If it doesn't exist, return a default value\n",
        "        return 'UNKNOWN'\n",
        "\n",
        "print(\"Extracting brand names...\")\n",
        "# Apply our new, safer function to the catalog_content\n",
        "train_df['brand'] = train_df['catalog_content'].apply(get_brand_from_catalog)\n",
        "test_df['brand'] = test_df['catalog_content'].apply(get_brand_from_catalog)\n",
        "\n",
        "# Encode the new 'brand' feature\n",
        "all_brands = pd.concat([train_df['brand'], test_df['brand']]).astype(str).unique()\n",
        "brand_encoder = LabelEncoder().fit(all_brands)\n",
        "train_df['brand_encoded'] = brand_encoder.transform(train_df['brand'].astype(str))\n",
        "test_df['brand_encoded'] = brand_encoder.transform(test_df['brand'].astype(str))\n",
        "print(\"Brand feature created.\")\n",
        "\n",
        "\n",
        "# --- 2. Create Interaction and Text Statistic Features (no changes here) ---\n",
        "print(\"Creating interaction and text statistic features...\")\n",
        "train_df['item_size'] = train_df['Value'] / (train_df['Pack_Size'] + 1e-6)\n",
        "test_df['item_size'] = test_df['Value'] / (test_df['Pack_Size'] + 1e-6)\n",
        "train_df['desc_length'] = train_df['clean_catalog_content'].str.len()\n",
        "test_df['desc_length'] = test_df['clean_catalog_content'].str.len()\n",
        "print(\"Additional features created.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Sample of New Features ---\")\n",
        "print(train_df[['brand', 'brand_encoded', 'item_size', 'desc_length']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1276a091",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "13fae1ef5b7946e3bc5fa79c23c06d57",
            "6f4bd829cc2c4d7b8378f2217f77f9ac",
            "7dd1800a7c6a4c168c699eace3089e83",
            "cc4ad365efd44cabae9b8bd69f364fa1",
            "09c3e7452d2c45dca030c8e30fd7b506",
            "b92c2988898146d4b8ebb5887d1cc654",
            "c62150b0dec64aa8ac7060cc315761c9",
            "bb7398d7df024d84a768f1da1e94aeda",
            "f5a7cd1157734115b01c5aa4fe24ac17",
            "74c54fdcc87c49b5b7b72d2f9c3e6c22",
            "6ac058876f6343fe82fc0050fea08f32",
            "42aaeaaad8e24bcb98324243d16840c2",
            "6db61befee504eacb1e40adbff3be8b9",
            "728e62f8dfd143de8b39497664ac9d82",
            "ac6ceca9a1d24074badcb9b1d14e749e",
            "0345115c50ea437ba86c1e54d39472a5",
            "a45d099b4fe64553b33c53e8568e2110",
            "9b3b5f80f1824db995f1550bb8e81a7d",
            "d738e93774384ffb9c1451385b858acf",
            "55b98cc8fa4943519d9f0517ca9c2922",
            "a90bce5c599244b1b8bbe12d2f2e4b39",
            "0cfc2d9de67b4ce6b6ae0b646a606b30"
          ]
        },
        "id": "1276a091",
        "outputId": "ae531919-fd4b-4948-8922-9f21d00799dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating text embeddings for training data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2dfb3269ed44ffdb48e427a070daf93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2344 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating text embeddings for test data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0b71f92f4544b37a3a9096926742d6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2344 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text embedding shape for training data: (75000, 384)\n",
            "Sample text embedding DataFrame:\n",
            "      txt_0     txt_1     txt_2     txt_3     txt_4     txt_5     txt_6  \\\n",
            "0  0.033260  0.010840 -0.056023  0.088746 -0.000599  0.023403  0.090809   \n",
            "1 -0.042282  0.031434 -0.047481  0.068237  0.012065 -0.059747  0.098276   \n",
            "2 -0.033634  0.003008  0.016667  0.083491  0.001591  0.052957  0.075054   \n",
            "3 -0.107012 -0.079453  0.012586 -0.057814  0.087116  0.024524  0.051916   \n",
            "4  0.054223  0.072425 -0.043134  0.051806 -0.111483  0.008939  0.054103   \n",
            "\n",
            "      txt_7     txt_8     txt_9  ...   txt_374   txt_375   txt_376   txt_377  \\\n",
            "0  0.043927  0.066413 -0.065356  ... -0.009825 -0.031103  0.042088 -0.018127   \n",
            "1  0.060108 -0.034569 -0.070540  ... -0.002846 -0.061159  0.005115  0.020050   \n",
            "2 -0.051422  0.032575 -0.090444  ...  0.011707  0.032602 -0.012787 -0.041831   \n",
            "3  0.117095 -0.001588 -0.057859  ... -0.005596 -0.037883 -0.032917 -0.006095   \n",
            "4  0.001732  0.045346 -0.095735  ... -0.014247  0.006413  0.023814  0.029915   \n",
            "\n",
            "    txt_378   txt_379   txt_380   txt_381   txt_382   txt_383  \n",
            "0 -0.024876  0.017959  0.017674 -0.058491  0.001500 -0.009657  \n",
            "1  0.095334 -0.001726  0.098191 -0.070830 -0.034437  0.026366  \n",
            "2 -0.013877 -0.007768  0.032651 -0.050687 -0.028666  0.016872  \n",
            "3  0.108860 -0.048802 -0.020941 -0.063594  0.047193  0.000133  \n",
            "4 -0.003298 -0.039553  0.118119 -0.086265 -0.012085 -0.026015  \n",
            "\n",
            "[5 rows x 384 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the sentence transformer model\n",
        "text_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "# Generate embeddings for the training data\n",
        "print(\"Generating text embeddings for training data...\")\n",
        "train_text_embeddings = text_model.encode(train_df['catalog_content'].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Generate embeddings for the test data\n",
        "print(\"Generating text embeddings for test data...\")\n",
        "test_text_embeddings = text_model.encode(test_df['catalog_content'].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Convert to DataFrames\n",
        "train_text_embed_df = pd.DataFrame(train_text_embeddings, columns=[f'txt_{i}' for i in range(train_text_embeddings.shape[1])])\n",
        "test_text_embed_df = pd.DataFrame(test_text_embeddings, columns=[f'txt_{i}' for i in range(test_text_embeddings.shape[1])])\n",
        "\n",
        "\n",
        "print(f\"\\nText embedding shape for training data: {train_text_embed_df.shape}\")\n",
        "print(\"Sample text embedding DataFrame:\")\n",
        "print(train_text_embed_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e8829b5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Image folder 'images' found. Proceeding with embedding.\n",
            "\n",
            "Generating image embeddings for training data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c5e6146dcba4ad3aac171a116a07403",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating image embeddings for test data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c841bcd4e00f4b5ebad1476f47e7b657",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Image embedding shape: (75000, 1280)\n",
            "Sample of new image embedding DataFrame (should NOT be all zeros):\n",
            "      img_0     img_1     img_2     img_3     img_4     img_5     img_6  \\\n",
            "0  0.769687 -0.132709 -0.178352 -0.177337  0.413674 -0.205476 -0.154951   \n",
            "1 -0.155376  0.089499 -0.086478  0.102381 -0.097783 -0.173205 -0.103229   \n",
            "2  0.270712  0.376103 -0.093395 -0.087051  0.131627 -0.128294 -0.039503   \n",
            "3  0.339731 -0.096009 -0.031545  0.292460 -0.157695 -0.199246  0.413247   \n",
            "4  0.170393 -0.070643 -0.174141 -0.099730 -0.123365 -0.222346  0.000466   \n",
            "\n",
            "      img_7     img_8     img_9  ...  img_1270  img_1271  img_1272  img_1273  \\\n",
            "0 -0.125823  0.476310 -0.152682  ... -0.144723 -0.140334 -0.075375 -0.212962   \n",
            "1 -0.035747 -0.054104 -0.101846  ... -0.159194 -0.084343 -0.022761  0.758022   \n",
            "2 -0.057429  0.657255  0.008079  ...  0.136017 -0.120255 -0.096028  0.234427   \n",
            "3 -0.047835  0.613992 -0.070078  ... -0.079402 -0.084615  0.010236 -0.222005   \n",
            "4  0.010950  0.440438 -0.104971  ... -0.169530 -0.197229 -0.110635 -0.214717   \n",
            "\n",
            "   img_1274  img_1275  img_1276  img_1277  img_1278  img_1279  \n",
            "0 -0.152951 -0.188482  0.304654 -0.138671 -0.173892 -0.074949  \n",
            "1  0.995141 -0.166634  0.478090 -0.152811  1.079516 -0.086888  \n",
            "2 -0.156869  0.135914  0.299563 -0.002932  0.009237 -0.082260  \n",
            "3 -0.118699 -0.009325 -0.001613 -0.029377 -0.090987 -0.055441  \n",
            "4 -0.182481 -0.218970  1.227705 -0.108635 -0.036887 -0.160287  \n",
            "\n",
            "[5 rows x 1280 columns]\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Generate Image Embeddings from Local Files\n",
        "\n",
        "# --- Check if the image folder exists ---\n",
        "IMAGE_FOLDER = 'images' \n",
        "if not os.path.exists(IMAGE_FOLDER):\n",
        "    print(f\" ERROR: The '{IMAGE_FOLDER}' directory was not found.\")\n",
        "    print(\"Please run the image download cell first.\")\n",
        "else:\n",
        "    print(f\" Image folder '{IMAGE_FOLDER}' found. Proceeding with embedding.\")\n",
        "\n",
        "# --- Image Model Setup (remains the same) ---\n",
        "img_model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0, global_pool='avg').to(device)\n",
        "img_model.eval()\n",
        "config = img_model.default_cfg\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(config['input_size'][1:]),\n",
        "    transforms.CenterCrop(config['input_size'][1:]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=config['mean'], std=config['std']),\n",
        "])\n",
        "\n",
        "# --- Image Feature Extraction Function ---\n",
        "def get_image_embedding(sample_id, model, device, transform, image_folder=IMAGE_FOLDER):\n",
        "    image_path = os.path.join(image_folder, f\"{sample_id}.jpg\")\n",
        "    \n",
        "    if not os.path.exists(image_path):\n",
        "        return np.zeros(1280)\n",
        "        \n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        batch_img = transform(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            embedding = model(batch_img)\n",
        "        return embedding.cpu().numpy().flatten()\n",
        "    except Exception as e:\n",
        "        return np.zeros(1280)\n",
        "\n",
        "# --- Generate Image Embeddings ---\n",
        "print(\"\\nGenerating image embeddings for training data...\")\n",
        "train_image_embeddings = train_df['sample_id'].progress_apply(\n",
        "    lambda x: get_image_embedding(x, img_model, device, transform)\n",
        ")\n",
        "\n",
        "print(\"Generating image embeddings for test data...\")\n",
        "test_image_embeddings = test_df['sample_id'].progress_apply(\n",
        "    lambda x: get_image_embedding(x, img_model, device, transform)\n",
        ")\n",
        "\n",
        "# --- Convert to DataFrames ---\n",
        "train_img_embed_df = pd.DataFrame(train_image_embeddings.to_list(), columns=[f'img_{i}' for i in range(1280)])\n",
        "test_img_embed_df = pd.DataFrame(test_image_embeddings.to_list(), columns=[f'img_{i}' for i in range(1280)])\n",
        "\n",
        "print(f\"\\nImage embedding shape: {train_img_embed_df.shape}\")\n",
        "print(\"Sample of new image embedding DataFrame (should NOT be all zeros):\")\n",
        "print(train_img_embed_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192dc1d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192dc1d4",
        "outputId": "45a01cad-5fcf-4c2b-fd21-f574317db907"
      },
      "outputs": [],
      "source": [
        "# # Select the engineered features from the original dataframes\n",
        "# #dont run nowww (old one)\n",
        "\n",
        "# numerical_features = ['Pack_Size', 'Value', 'Unit_Encoded']\n",
        "# X_train_base = train_df[numerical_features].fillna(0)\n",
        "# X_test_base = test_df[numerical_features].fillna(0)\n",
        "\n",
        "# # Combine all features\n",
        "# X_train = pd.concat([X_train_base, train_text_embed_df, train_img_embed_df], axis=1)\n",
        "# X_test = pd.concat([X_test_base, test_text_embed_df, test_img_embed_df], axis=1)\n",
        "\n",
        "# # Prepare target variable - using log transform for better performance\n",
        "# y_train = train_df['price']\n",
        "# y_train_log = np.log1p(y_train)\n",
        "\n",
        "# print(\"--- Final Combined Datasets ---\")\n",
        "# print(f\"X_train shape: {X_train.shape}\")\n",
        "# print(f\"X_test shape: {X_test.shape}\")\n",
        "# print(f\"y_train_log shape: {y_train_log.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e09bb7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Combining All Features\n",
            "============================================================\n",
            "X_train shape: (75000, 1670)\n",
            "X_test shape: (75000, 1670)\n",
            "y_train_log shape: (75000,)\n",
            "\n",
            "Using 15 numerical/categorical features.\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Combine All Features (Using Log Features)\n",
        "\n",
        "# Use our new log-transformed numerical features\n",
        "numerical_features = ['Pack_Size_log', 'Value_log', 'Unit_Encoded', 'brand_encoded', 'item_size','desc_length']\n",
        "X_train_base = train_df[numerical_features]\n",
        "X_test_base = test_df[numerical_features]\n",
        "\n",
        "# Combine all features (assuming embed dfs are created)\n",
        "X_train = pd.concat([X_train_base, train_text_embed_df, train_img_embed_df], axis=1)\n",
        "X_test = pd.concat([X_test_base, test_text_embed_df, test_img_embed_df], axis=1)\n",
        "\n",
        "# Go back to predicting the log of the original price\n",
        "y_train = train_df['price']\n",
        "y_train_log = np.log1p(train_df['price'])\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"Using features: {numerical_features}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "66c921ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Combining All Features\n",
            "============================================================\n",
            "X_train shape: (75000, 1670)\n",
            "X_test shape: (75000, 1670)\n",
            "y_train_log shape: (75000,)\n",
            "\n",
            "Using the following 6 numerical/categorical features:\n",
            "['Pack_Size_log', 'Value_log', 'Unit_Encoded', 'brand_encoded', 'item_size', 'desc_length']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Combining All Features\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define the complete list of all engineered numerical and categorical features\n",
        "numerical_features = [\n",
        "    'Pack_Size_log', \n",
        "    'Value_log', \n",
        "    'Unit_Encoded', \n",
        "    'brand_encoded', \n",
        "    'item_size',\n",
        "    'desc_length'\n",
        "]\n",
        "\n",
        "# Select the base numerical features, filling any potential NaNs with 0 for safety\n",
        "X_train_base = train_df[numerical_features].fillna(0)\n",
        "X_test_base = test_df[numerical_features].fillna(0)\n",
        "\n",
        "\n",
        "# Combine all feature sets into the final training matrix\n",
        "# reset_index(drop=True) is used to ensure a clean, continuous index for concatenation\n",
        "X_train = pd.concat([\n",
        "    X_train_base.reset_index(drop=True), \n",
        "    train_text_embed_df.reset_index(drop=True), \n",
        "    train_img_embed_df.reset_index(drop=True)\n",
        "], axis=1)\n",
        "\n",
        "# Combine all feature sets into the final test matrix\n",
        "X_test = pd.concat([\n",
        "    X_test_base.reset_index(drop=True), \n",
        "    test_text_embed_df.reset_index(drop=True), \n",
        "    test_img_embed_df.reset_index(drop=True)\n",
        "], axis=1)\n",
        "\n",
        "# Prepare the target variable, using a log transform for model stability\n",
        "y_train = train_df['price']\n",
        "y_train_log = np.log1p(y_train)\n",
        "\n",
        "# Print the final shapes and features used to verify everything is correct\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train_log shape: {y_train_log.shape}\")\n",
        "print(f\"\\nUsing the following {len(numerical_features)} numerical/categorical features:\")\n",
        "print(numerical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "68108312",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Creating Train/Validation Split\n",
            "============================================================\n",
            "Training split shape: (60000, 1670)\n",
            "Validation split shape: (15000, 1670)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Creating Train/Validation Split\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_train_split, X_val, y_train_log_split, y_val_log = train_test_split(\n",
        "    X_train, y_train_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training split shape: {X_train_split.shape}\")\n",
        "print(f\"Validation split shape: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "d8ab9df3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def smape(y_true, y_pred):\n",
        "    \"\"\"Symmetric Mean Absolute Percentage Error\"\"\"\n",
        "    numerator = np.abs(y_pred - y_true)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    return np.mean(numerator / denominator) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "daf3934f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class PriceDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for price prediction\"\"\"\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = torch.FloatTensor(X.values if isinstance(X, pd.DataFrame) else X)\n",
        "        self.y = torch.FloatTensor(y.values if y is not None else np.zeros(len(X)))\n",
        "        self.has_labels = y is not None\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.has_labels:\n",
        "            return self.X[idx], self.y[idx]\n",
        "        return self.X[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "28a3d803",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class SimpleMLP(nn.Module):\n",
        "    \"\"\"Simple MLP for price prediction\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dims=[512, 256, 128, 64], dropout=0.3):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        \n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        layers.append(nn.Linear(prev_dim, 1))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.network(x).squeeze()\n",
        "\n",
        "\n",
        "class AdvancedMultimodalMLP(nn.Module):\n",
        "    \"\"\"Advanced MLP with separate branches for different feature types\"\"\"\n",
        "    def __init__(self, num_features, text_features, img_features):\n",
        "        super(AdvancedMultimodalMLP, self).__init__()\n",
        "        \n",
        "        self.num_features = num_features\n",
        "        self.text_features = text_features\n",
        "        self.img_features = img_features\n",
        "        \n",
        "        # Numerical features branch\n",
        "        self.num_net = nn.Sequential(\n",
        "            nn.Linear(num_features, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "        \n",
        "        # Text features branch\n",
        "        self.text_net = nn.Sequential(\n",
        "            nn.Linear(text_features, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "        \n",
        "        # Image features branch\n",
        "        self.img_net = nn.Sequential(\n",
        "            nn.Linear(img_features, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256)\n",
        "        )\n",
        "        \n",
        "        # Fusion layer\n",
        "        fusion_input_dim = 32 + 128 + 256\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(fusion_input_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Split input into different modalities\n",
        "        num_feat = x[:, :self.num_features]\n",
        "        text_feat = x[:, self.num_features:self.num_features+self.text_features]\n",
        "        img_feat = x[:, self.num_features+self.text_features:]\n",
        "        \n",
        "        # Process each modality\n",
        "        num_out = self.num_net(num_feat)\n",
        "        text_out = self.text_net(text_feat)\n",
        "        img_out = self.img_net(img_feat)\n",
        "        \n",
        "        # Fuse and predict\n",
        "        combined = torch.cat([num_out, text_out, img_out], dim=1)\n",
        "        output = self.fusion(combined)\n",
        "        \n",
        "        return output.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "aaff5bfa",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_mlp(X_train, y_train, X_val, y_val, \n",
        "              model_type='simple',\n",
        "              num_epochs=100, \n",
        "              batch_size=256, \n",
        "              lr=0.001,\n",
        "              num_features=3,\n",
        "              text_features=384,\n",
        "              img_features=1280):\n",
        "    \"\"\"Train MLP model\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {model_type.upper()} MLP Model\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = PriceDataset(X_train_scaled, y_train)\n",
        "    val_dataset = PriceDataset(X_val_scaled, y_val)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    # Initialize model\n",
        "    input_dim = X_train.shape[1]\n",
        "    \n",
        "    if model_type == 'simple':\n",
        "        model = SimpleMLP(input_dim).to(device)\n",
        "    else:  # advanced\n",
        "        model = AdvancedMultimodalMLP(num_features, text_features, img_features).to(device)\n",
        "    \n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "    \n",
        "    # Training loop\n",
        "    best_smape = float('inf')\n",
        "    patience_counter = 0\n",
        "    patience = 15\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        \n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_losses.append(loss.item())\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                predictions = model(X_batch)\n",
        "                loss = criterion(predictions, y_batch)\n",
        "                \n",
        "                val_losses.append(loss.item())\n",
        "                all_preds.extend(predictions.cpu().numpy())\n",
        "                all_targets.extend(y_batch.cpu().numpy())\n",
        "        \n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        val_smape = smape(np.expm1(all_targets), np.expm1(all_preds))\n",
        "        \n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        # Print progress\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "                  f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "                  f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "                  f\"Val SMAPE: {val_smape:.4f}%\")\n",
        "        \n",
        "        # Early stopping\n",
        "        if val_smape < best_smape:\n",
        "            best_smape = val_smape\n",
        "            patience_counter = 0\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'scaler': scaler,\n",
        "                'best_smape': best_smape,\n",
        "            }, 'best_mlp_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "    \n",
        "    # Load best model\n",
        "    checkpoint = torch.load('best_mlp_model.pth', map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    scaler = checkpoint['scaler']\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Best Validation SMAPE: {best_smape:.4f}%\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    return model, scaler, best_smape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "645f3fd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Training SIMPLE MLP Model\n",
            "============================================================\n",
            "Model parameters: 1,030,017\n",
            "Epoch [5/100] Train Loss: 0.5277 | Val Loss: 0.5444 | Val SMAPE: 56.1170%\n",
            "Epoch [10/100] Train Loss: 0.3791 | Val Loss: 0.5226 | Val SMAPE: 53.9202%\n",
            "Epoch [15/100] Train Loss: 0.2777 | Val Loss: 0.5338 | Val SMAPE: 53.5747%\n",
            "Epoch [20/100] Train Loss: 0.2011 | Val Loss: 0.5256 | Val SMAPE: 53.0377%\n",
            "Epoch [25/100] Train Loss: 0.1668 | Val Loss: 0.5223 | Val SMAPE: 52.5137%\n",
            "Epoch [30/100] Train Loss: 0.1507 | Val Loss: 0.5236 | Val SMAPE: 52.2157%\n",
            "Epoch [35/100] Train Loss: 0.1391 | Val Loss: 0.5171 | Val SMAPE: 52.0618%\n",
            "Epoch [40/100] Train Loss: 0.1365 | Val Loss: 0.5192 | Val SMAPE: 52.0492%\n",
            "Epoch [45/100] Train Loss: 0.1336 | Val Loss: 0.5146 | Val SMAPE: 52.0428%\n",
            "Epoch [50/100] Train Loss: 0.1299 | Val Loss: 0.5159 | Val SMAPE: 52.0067%\n",
            "Epoch [55/100] Train Loss: 0.1266 | Val Loss: 0.5165 | Val SMAPE: 51.9169%\n",
            "Epoch [60/100] Train Loss: 0.1248 | Val Loss: 0.5175 | Val SMAPE: 51.9581%\n",
            "Epoch [65/100] Train Loss: 0.1242 | Val Loss: 0.5167 | Val SMAPE: 51.9829%\n",
            "Epoch [70/100] Train Loss: 0.1240 | Val Loss: 0.5195 | Val SMAPE: 51.9726%\n",
            "Epoch [75/100] Train Loss: 0.1229 | Val Loss: 0.5165 | Val SMAPE: 51.9417%\n",
            "\n",
            "Early stopping at epoch 76\n",
            "\n",
            "============================================================\n",
            "Best Validation SMAPE: 51.9169%\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_3720\\1727071095.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('best_mlp_model.pth', map_location=device)\n"
          ]
        }
      ],
      "source": [
        "mlp_simple, scaler_simple, smape_simple = train_mlp(\n",
        "    X_train_split, \n",
        "    y_train_log_split, \n",
        "    X_val, \n",
        "    y_val_log,\n",
        "    model_type='simple',\n",
        "    num_epochs=100,\n",
        "    batch_size=256,\n",
        "    lr=0.001\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "7673d742",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using feature counts -> Numerical: 6, Text: 384, Image: 1280\n",
            "\n",
            "============================================================\n",
            "Training ADVANCED MLP Model\n",
            "============================================================\n",
            "Model parameters: 1,071,585\n",
            "Epoch [5/100] Train Loss: 0.4439 | Val Loss: 0.5381 | Val SMAPE: 55.4050%\n",
            "Epoch [10/100] Train Loss: 0.3196 | Val Loss: 0.5089 | Val SMAPE: 53.1061%\n",
            "Epoch [15/100] Train Loss: 0.2401 | Val Loss: 0.5139 | Val SMAPE: 52.4647%\n",
            "Epoch [20/100] Train Loss: 0.1641 | Val Loss: 0.5116 | Val SMAPE: 51.9544%\n",
            "Epoch [25/100] Train Loss: 0.1341 | Val Loss: 0.5114 | Val SMAPE: 51.4840%\n",
            "Epoch [30/100] Train Loss: 0.1147 | Val Loss: 0.5113 | Val SMAPE: 51.2936%\n",
            "Epoch [35/100] Train Loss: 0.1080 | Val Loss: 0.5119 | Val SMAPE: 51.3173%\n",
            "Epoch [40/100] Train Loss: 0.1006 | Val Loss: 0.5118 | Val SMAPE: 51.3815%\n",
            "Epoch [45/100] Train Loss: 0.0985 | Val Loss: 0.5113 | Val SMAPE: 51.4854%\n",
            "Epoch [50/100] Train Loss: 0.0980 | Val Loss: 0.5098 | Val SMAPE: 51.4403%\n",
            "Epoch [55/100] Train Loss: 0.0960 | Val Loss: 0.5112 | Val SMAPE: 51.3596%\n",
            "Epoch [60/100] Train Loss: 0.0956 | Val Loss: 0.5102 | Val SMAPE: 51.3496%\n",
            "Epoch [65/100] Train Loss: 0.0948 | Val Loss: 0.5126 | Val SMAPE: 51.3727%\n",
            "Epoch [70/100] Train Loss: 0.0954 | Val Loss: 0.5115 | Val SMAPE: 51.2956%\n",
            "\n",
            "Early stopping at epoch 71\n",
            "\n",
            "============================================================\n",
            "Best Validation SMAPE: 51.2146%\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_3720\\1727071095.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('best_mlp_model.pth', map_location=device)\n"
          ]
        }
      ],
      "source": [
        "# Define the numerical features list EXACTLY as you did in the combination cell\n",
        "numerical_features_list = [\n",
        "    'Pack_Size_log', \n",
        "    'Value_log', \n",
        "    'Unit_Encoded', \n",
        "    'brand_encoded', \n",
        "    'item_size',\n",
        "    'desc_length'\n",
        "]\n",
        "\n",
        "num_features_count = len(numerical_features_list)\n",
        "text_features_count = train_text_embed_df.shape[1]\n",
        "img_features_count = train_img_embed_df.shape[1]\n",
        "\n",
        "print(f\"Using feature counts -> Numerical: {num_features_count}, Text: {text_features_count}, Image: {img_features_count}\")\n",
        "# --------------------------------\n",
        "\n",
        "mlp_advanced, scaler_advanced, smape_advanced = train_mlp(\n",
        "    X_train_split, \n",
        "    y_train_log_split, \n",
        "    X_val, \n",
        "    y_val_log,\n",
        "    model_type='advanced',\n",
        "    num_epochs=100,\n",
        "    batch_size=256,\n",
        "    lr=0.001,\n",
        "    num_features=num_features_count,    # <-- Use the correct count\n",
        "    text_features=text_features_count,  # <-- Use the correct count\n",
        "    img_features=img_features_count     # <-- Use the correct count\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "945bcc23",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Generating Final Predictions for Submission\n",
            "============================================================\n",
            "Loading best model checkpoint from 'best_mlp_model.pth'...\n",
            "Model loaded. Best validation SMAPE was: 51.2146%\n",
            "Scaling test data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_3720\\2920498085.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('best_mlp_model.pth', map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating predictions on the test set...\n",
            "\n",
            "Submission file 'submission.csv' created successfully!\n",
            "--- Submission File Head ---\n",
            "   sample_id      price\n",
            "0     100179  18.924973\n",
            "1     245611  25.577932\n",
            "2     146263  19.809526\n",
            "3      95658   4.585983\n",
            "4      36806  24.854664\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Final Predictions for Submission\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load the best model and scaler from the last training run (Advanced MLP)\n",
        "print(\"Loading best model checkpoint from 'best_mlp_model.pth'...\")\n",
        "checkpoint = torch.load('best_mlp_model.pth', map_location=device)\n",
        "\n",
        "# Initialize the model architecture with the correct feature dimensions\n",
        "num_features_count = len(numerical_features)\n",
        "text_features_count = test_text_embed_df.shape[1]\n",
        "img_features_count = test_img_embed_df.shape[1]\n",
        "final_model = AdvancedMultimodalMLP(num_features_count, text_features_count, img_features_count).to(device)\n",
        "\n",
        "# Load the trained weights and the scaler\n",
        "final_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "final_scaler = checkpoint['scaler']\n",
        "print(f\"Model loaded. Best validation SMAPE was: {checkpoint['best_smape']:.4f}%\")\n",
        "\n",
        "# Prepare the test data\n",
        "print(\"Scaling test data...\")\n",
        "X_test_scaled = final_scaler.transform(X_test)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
        "\n",
        "# Generate predictions\n",
        "print(\"Generating predictions on the test set...\")\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    log_predictions = final_model(X_test_tensor)\n",
        "\n",
        "# Convert log predictions back to original price scale\n",
        "# .cpu().numpy() moves the tensor from GPU to CPU and converts to a NumPy array\n",
        "final_predictions = np.expm1(log_predictions.cpu().numpy())\n",
        "\n",
        "# Ensure prices are non-negative\n",
        "final_predictions[final_predictions < 0] = 0\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],\n",
        "    'price': final_predictions\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"\\nSubmission file 'submission.csv' created successfully!\")\n",
        "print(\"--- Submission File Head ---\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9742aa52",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f68c44c",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4f68c44c",
        "outputId": "ca1614f6-02bb-4260-eb2d-384d67c8541e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-mae:0.75604\tval-mae:0.76571\n",
            "[100]\ttrain-mae:0.59833\tval-mae:0.62730\n",
            "[200]\ttrain-mae:0.55978\tval-mae:0.60247\n",
            "[300]\ttrain-mae:0.53402\tval-mae:0.58976\n",
            "[400]\ttrain-mae:0.51438\tval-mae:0.58212\n",
            "[500]\ttrain-mae:0.49768\tval-mae:0.57577\n",
            "[600]\ttrain-mae:0.48293\tval-mae:0.57132\n",
            "[700]\ttrain-mae:0.46946\tval-mae:0.56780\n",
            "[800]\ttrain-mae:0.45662\tval-mae:0.56445\n",
            "[900]\ttrain-mae:0.44502\tval-mae:0.56220\n",
            "[1000]\ttrain-mae:0.43379\tval-mae:0.55969\n",
            "[1100]\ttrain-mae:0.42297\tval-mae:0.55762\n",
            "[1200]\ttrain-mae:0.41295\tval-mae:0.55568\n",
            "[1300]\ttrain-mae:0.40313\tval-mae:0.55400\n",
            "[1400]\ttrain-mae:0.39361\tval-mae:0.55266\n",
            "[1500]\ttrain-mae:0.38414\tval-mae:0.55125\n",
            "[1600]\ttrain-mae:0.37546\tval-mae:0.54997\n",
            "[1700]\ttrain-mae:0.36693\tval-mae:0.54871\n",
            "[1800]\ttrain-mae:0.35870\tval-mae:0.54744\n",
            "[1900]\ttrain-mae:0.35063\tval-mae:0.54636\n",
            "[2000]\ttrain-mae:0.34269\tval-mae:0.54512\n",
            "[2100]\ttrain-mae:0.33532\tval-mae:0.54416\n",
            "[2200]\ttrain-mae:0.32814\tval-mae:0.54327\n",
            "[2300]\ttrain-mae:0.32109\tval-mae:0.54237\n",
            "[2400]\ttrain-mae:0.31430\tval-mae:0.54151\n",
            "[2500]\ttrain-mae:0.30755\tval-mae:0.54055\n",
            "[2600]\ttrain-mae:0.30106\tval-mae:0.53981\n",
            "[2700]\ttrain-mae:0.29467\tval-mae:0.53899\n",
            "[2800]\ttrain-mae:0.28855\tval-mae:0.53832\n",
            "[2900]\ttrain-mae:0.28248\tval-mae:0.53762\n",
            "[3000]\ttrain-mae:0.27675\tval-mae:0.53705\n",
            "[3100]\ttrain-mae:0.27111\tval-mae:0.53640\n",
            "[3200]\ttrain-mae:0.26549\tval-mae:0.53587\n",
            "[3300]\ttrain-mae:0.26016\tval-mae:0.53527\n",
            "[3400]\ttrain-mae:0.25498\tval-mae:0.53469\n",
            "[3500]\ttrain-mae:0.24989\tval-mae:0.53417\n",
            "[3600]\ttrain-mae:0.24493\tval-mae:0.53357\n",
            "[3700]\ttrain-mae:0.23998\tval-mae:0.53312\n",
            "[3800]\ttrain-mae:0.23531\tval-mae:0.53271\n",
            "[3900]\ttrain-mae:0.23080\tval-mae:0.53219\n",
            "[4000]\ttrain-mae:0.22636\tval-mae:0.53188\n",
            "[4100]\ttrain-mae:0.22190\tval-mae:0.53146\n",
            "[4200]\ttrain-mae:0.21765\tval-mae:0.53103\n",
            "[4300]\ttrain-mae:0.21357\tval-mae:0.53070\n",
            "[4400]\ttrain-mae:0.20961\tval-mae:0.53039\n",
            "[4500]\ttrain-mae:0.20559\tval-mae:0.53009\n",
            "[4600]\ttrain-mae:0.20183\tval-mae:0.52996\n",
            "[4700]\ttrain-mae:0.19808\tval-mae:0.52973\n",
            "[4800]\ttrain-mae:0.19436\tval-mae:0.52947\n",
            "[4900]\ttrain-mae:0.19068\tval-mae:0.52913\n",
            "[4999]\ttrain-mae:0.18715\tval-mae:0.52879\n",
            "\n",
            "-------------------------------------------\n",
            "Validation SMAPE Score (XGBoost): 53.1493%\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Split data into training and validation sets\n",
        "X_train_split, X_val, y_train_log_split, y_val_log = train_test_split(\n",
        "    X_train, y_train_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Convert to DMatrix format (recommended for XGBoost)\n",
        "dtrain = xgb.DMatrix(X_train_split, label=y_train_log_split)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_log)\n",
        "\n",
        "# ✅ XGBoost parameters (analogous to LightGBM setup)\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'mae',\n",
        "    'learning_rate': 0.03,\n",
        "    'seed': 42,\n",
        "    \n",
        "    # --- Key Changes to Reduce Overfitting ---\n",
        "    'max_depth': 5,               # DECREASED: The single most important change. Forces simpler trees.\n",
        "    'subsample': 0.7,             # DECREASED: Use a smaller random sample of data for each tree.\n",
        "    'colsample_bytree': 0.7,      # DECREASED: Use a smaller random sample of features for each tree.\n",
        "    'alpha': 2,                   # INCREASED: Stronger L1 regularization penalty.\n",
        "    'lambda': 2,                  # INCREASED: Stronger L2 regularization penalty.\n",
        "    'min_child_weight': 5  \n",
        "}\n",
        "\n",
        "# ✅ Train model with early stopping\n",
        "evals = [(dtrain, 'train'), (dval, 'val')]\n",
        "xgb_model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=5000,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=100,\n",
        "    verbose_eval=100  # show progress every 100 rounds\n",
        ")\n",
        "\n",
        "# ✅ Make predictions on validation set\n",
        "val_preds_log = xgb_model.predict(dval)\n",
        "\n",
        "# ✅ Convert predictions back from log scale\n",
        "val_preds = np.expm1(val_preds_log)\n",
        "y_val_true = np.expm1(y_val_log)\n",
        "\n",
        "# ✅ Define SMAPE function if not already defined\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "#  Calculate SMAPE\n",
        "validation_smape = smape(y_val_true, val_preds)\n",
        "\n",
        "print(\"\\n-------------------------------------------\")\n",
        "print(f\"Validation SMAPE Score (XGBoost): {validation_smape:.4f}%\")\n",
        "print(\"-------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bc909579",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diagnosing overfitting...\n",
            "\n",
            "SMAPE on Training Data (80%): 20.6967%\n",
            "SMAPE on Validation Data (20%): 53.1493%\n",
            "---------------------------------\n",
            " Result: High Overfitting Detected! Gap: 32.45%.\n"
          ]
        }
      ],
      "source": [
        "# Cell 6c: Overfitting Diagnosis for XGBoost (Corrected)\n",
        "\n",
        "print(\"Diagnosing overfitting...\")\n",
        "\n",
        "# --- THIS IS THE FIX ---\n",
        "# Convert the training split DataFrame to a DMatrix before predicting\n",
        "dtrain_split_for_pred = xgb.DMatrix(X_train_split)\n",
        "\n",
        "# Predict on the TRAINING data using the new DMatrix\n",
        "train_preds_log = xgb_model.predict(dtrain_split_for_pred, iteration_range=(0, xgb_model.best_iteration))\n",
        "train_preds = np.expm1(train_preds_log)\n",
        "y_train_true = np.expm1(y_train_log_split)\n",
        "\n",
        "# Calculate training SMAPE\n",
        "training_smape = smape(y_train_true, train_preds)\n",
        "\n",
        "# --- Overfitting Diagnosis ---\n",
        "print(f\"\\nSMAPE on Training Data (80%): {training_smape:.4f}%\")\n",
        "print(f\"SMAPE on Validation Data (20%): {validation_smape:.4f}%\")\n",
        "print(\"---------------------------------\")\n",
        "gap = validation_smape - training_smape\n",
        "if gap > 15:\n",
        "    print(f\" Result: High Overfitting Detected! Gap: {gap:.2f}%.\")\n",
        "elif gap > 5:\n",
        "    print(f\" Result: Moderate Overfitting. Gap: {gap:.2f}%.\")\n",
        "else:\n",
        "    print(\" Result: Good Fit. The model is generalizing well.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f18e141",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting final model training on all data...\")\n",
        "\n",
        "# Create a DMatrix for the full training data\n",
        "dtrain_full = xgb.DMatrix(X_train, label=y_train_log)\n",
        "\n",
        "# Use the same parameters from validation, but train for the optimal number of rounds\n",
        "# 'xgb_model.best_iteration' was found in the validation step (Cell 6b)\n",
        "best_rounds = xgb_model.best_iteration \n",
        "print(f\"Training for {best_rounds} rounds...\")\n",
        "\n",
        "# Train the final model\n",
        "final_xgb_model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain_full,\n",
        "    num_boost_round=best_rounds,\n",
        "    verbose_eval=100 # Optional: shows progress\n",
        ")\n",
        "\n",
        "print(\"Final model training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0227df9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Cell 7a: Train Final LightGBM Model and Get Predictions\n",
        "\n",
        "# print(\"--- Training Final LightGBM Model ---\")\n",
        "\n",
        "# # Use the best parameters you found for LightGBM (e.g., the 'balanced' set)\n",
        "# lgbm_params = {\n",
        "#     'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 5000,\n",
        "#     'learning_rate': 0.03, 'seed': 42, 'n_jobs': -1, 'verbose': -1,\n",
        "#     'num_leaves': 51, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n",
        "#     'lambda_l1': 0.5, 'lambda_l2': 0.5, 'min_child_samples': 20\n",
        "# }\n",
        "\n",
        "# # We need a temporary validation set just to find the best number of rounds automatically\n",
        "# X_train_temp, X_val_temp, y_train_log_temp, y_val_log_temp = train_test_split(\n",
        "#     X_train, y_train_log, test_size=0.1, random_state=42\n",
        "# )\n",
        "\n",
        "# temp_lgbm_model = lgb.LGBMRegressor(**lgbm_params)\n",
        "# temp_lgbm_model.fit(X_train_temp, y_train_log_temp,\n",
        "#                     eval_set=[(X_val_temp, y_val_log_temp)],\n",
        "#                     callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "\n",
        "# # Get the best number of rounds and retrain a new model on ALL the data\n",
        "# best_rounds_lgbm = temp_lgbm_model.best_iteration_\n",
        "# print(f\"Retraining LightGBM on all data for {best_rounds_lgbm} rounds...\")\n",
        "# lgbm_params['n_estimators'] = best_rounds_lgbm # Set the optimal number of trees\n",
        "# final_lgbm_model = lgb.LGBMRegressor(**lgbm_params)\n",
        "# final_lgbm_model.fit(X_train, y_train_log)\n",
        "\n",
        "# # Predict on the test set and save the predictions to a file\n",
        "# lgbm_preds_log = final_lgbm_model.predict(X_test)\n",
        "# lgbm_preds = np.expm1(lgbm_preds_log)\n",
        "# np.save('lgbm_test_predictions.npy', lgbm_preds)\n",
        "\n",
        "# print(\"LightGBM predictions saved to 'lgbm_test_predictions.npy'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "652cae92",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training Final XGBoost Model ---\n",
            "Using device: cuda\n",
            "Training XGBoost on all data for 4999 rounds...\n",
            "XGBoost predictions saved to 'xgb_test_predictions.npy'\n"
          ]
        }
      ],
      "source": [
        "# Cell 7b: Train Final XGBoost Model and Get Predictions (with Modern GPU Syntax)\n",
        "\n",
        "print(\"\\n--- Training Final XGBoost Model ---\")\n",
        "\n",
        "# Use the best regularized parameters with the updated device parameter\n",
        "xgb_params = {\n",
        "    'objective': 'reg:squarederror', 'eval_metric': 'mae', 'learning_rate': 0.03,\n",
        "    'max_depth': 5, 'subsample': 0.7, 'colsample_bytree': 0.7,\n",
        "    'alpha': 2, 'lambda': 2, 'min_child_weight': 5, 'seed': 42,\n",
        "    \n",
        "    # --- THIS IS THE UPDATED PART ---\n",
        "    'tree_method': 'hist',\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "}\n",
        "\n",
        "print(f\"Using device: {xgb_params['device']}\") # Added a print to confirm\n",
        "\n",
        "# Create DMatrix for the full training data\n",
        "dtrain_full = xgb.DMatrix(X_train, label=y_train_log)\n",
        "\n",
        "# Get the optimal number of rounds from your validation step (Cell 6b)\n",
        "best_rounds_xgb = xgb_model.best_iteration \n",
        "print(f\"Training XGBoost on all data for {best_rounds_xgb} rounds...\")\n",
        "\n",
        "final_xgb_model = xgb.train(\n",
        "    params=xgb_params,\n",
        "    dtrain=dtrain_full,\n",
        "    num_boost_round=best_rounds_xgb,\n",
        "    verbose_eval=100 # Keep it clean\n",
        ")\n",
        "\n",
        "# Predict on the test set and save the predictions\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "xgb_preds_log = final_xgb_model.predict(dtest)\n",
        "xgb_preds = np.expm1(xgb_preds_log)\n",
        "np.save('xgb_test_predictions.npy', xgb_preds)\n",
        "\n",
        "print(\"XGBoost predictions saved to 'xgb_test_predictions.npy'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81108cbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Cell 8: Create Ensemble Submission\n",
        "\n",
        "# print(\"Creating final ensemble submission...\")\n",
        "\n",
        "# # Load the saved predictions from each model\n",
        "# lgbm_preds = np.load('lgbm_test_predictions.npy')\n",
        "# xgb_preds = np.load('xgb_test_predictions.npy')\n",
        "\n",
        "# # --- The Ensemble: Simple Averaging ---\n",
        "# ensemble_preds = (lgbm_preds + xgb_preds) / 2\n",
        "\n",
        "# # Ensure all predicted prices are positive floats\n",
        "# ensemble_preds[ensemble_preds < 0] = 0\n",
        "\n",
        "# # Create the submission DataFrame\n",
        "# submission_df = pd.DataFrame({\n",
        "#     'sample_id': test_df['sample_id'], \n",
        "#     'price': ensemble_preds\n",
        "# })\n",
        "\n",
        "# # Save the final submission file\n",
        "# submission_df.to_csv('submission_ensemble.csv', index=False)\n",
        "\n",
        "# print(\"\\nEnsemble submission file 'submission_ensemble.csv' created successfully.\")\n",
        "# print(\"--- File Head ---\")\n",
        "# print(submission_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "72716e9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating final ensemble submission with strict formatting...\n",
            "\n",
            "Ensemble submission file created successfully with 6-decimal-place precision.\n",
            "--- File Head ---\n",
            "   sample_id      price\n",
            "0     100179  16.333675\n",
            "1     245611  15.051077\n",
            "2     146263  17.806292\n",
            "3      95658   6.296509\n",
            "4      36806  27.668425\n"
          ]
        }
      ],
      "source": [
        "# # Cell 8: Create Ensemble Submission (with Strict Float Formatting)\n",
        "\n",
        "# print(\"Creating final ensemble submission with strict formatting...\")\n",
        "\n",
        "# # Load the saved predictions from each model\n",
        "# xgb_preds = np.load('xgb_test_predictions.npy')\n",
        "\n",
        "# # --- The Ensemble: Simple Averaging ---\n",
        "# ensemble_preds = xgb_preds\n",
        "\n",
        "# # Ensure all predicted prices are positive floats\n",
        "# ensemble_preds[ensemble_preds < 0] = 0\n",
        "\n",
        "# # --- Failsafe Step ---\n",
        "# # Reload a clean version of the test data to guarantee the sample_id column is correct.\n",
        "# submission_ids = pd.read_csv('dataset/test.csv')['sample_id']\n",
        "\n",
        "# # Create the submission DataFrame\n",
        "# submission_df = pd.DataFrame({\n",
        "#     'sample_id': submission_ids, \n",
        "#     'price': ensemble_preds\n",
        "# })\n",
        "\n",
        "# # Explicitly cast datatypes for maximum compatibility\n",
        "# submission_df['sample_id'] = submission_df['sample_id'].astype(int)\n",
        "# submission_df['price'] = submission_df['price'].astype(float)\n",
        "\n",
        "# # --- Crucial Formatting Change ---\n",
        "# # Save with a specific float format to ensure clean, 6-decimal-place numbers.\n",
        "# # '%.6f' formats the number as a float with exactly 6 digits after the decimal point.\n",
        "# submission_df.to_csv(\n",
        "#     'submission_ensemble.csv', \n",
        "#     index=False, \n",
        "#     float_format='%.6f' # <-- This is the key change\n",
        "# )\n",
        "# # -----------------------------\n",
        "\n",
        "# print(\"\\nEnsemble submission file created successfully with 6-decimal-place precision.\")\n",
        "# print(\"--- File Head ---\")\n",
        "# print(submission_df.head())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "capstone_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0345115c50ea437ba86c1e54d39472a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c9d866063f49fab46097c64152712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_224a0209137e4474b22e226363fefa3e",
            "placeholder": "​",
            "style": "IPY_MODEL_c778143adcbd4ee3b218825bca3748bd",
            "value": "100%"
          }
        },
        "09c3e7452d2c45dca030c8e30fd7b506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfc2d9de67b4ce6b6ae0b646a606b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e64710c23b34ed8b527db2c4021d426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12c7c0c4338240b2bad46e9c7173ab01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13fae1ef5b7946e3bc5fa79c23c06d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f4bd829cc2c4d7b8378f2217f77f9ac",
              "IPY_MODEL_7dd1800a7c6a4c168c699eace3089e83",
              "IPY_MODEL_cc4ad365efd44cabae9b8bd69f364fa1"
            ],
            "layout": "IPY_MODEL_09c3e7452d2c45dca030c8e30fd7b506"
          }
        },
        "15a6fad93bdb44a5ad0fb2ae74a28ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1896ee5252774706bdcc127c2014800b",
            "placeholder": "​",
            "style": "IPY_MODEL_bfdf3bf15e7744e7832780d2e80f83dc",
            "value": " 75000/75000 [00:01&lt;00:00, 85831.99it/s]"
          }
        },
        "184b8a10da6c4f3fb6dbbf02ba7e06b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1896ee5252774706bdcc127c2014800b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1978eacbf6cd4e0388dede497e41bce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4e89fb341d44fbfa3d37201d014b39c",
            "placeholder": "​",
            "style": "IPY_MODEL_0e64710c23b34ed8b527db2c4021d426",
            "value": " 75000/75000 [00:00&lt;00:00, 104036.44it/s]"
          }
        },
        "224a0209137e4474b22e226363fefa3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5140e4171e42629d313b3cd59f3756": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0563866ee6459facc0500ff19eb954": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05c9d866063f49fab46097c64152712a",
              "IPY_MODEL_fb41578f13694ad18385185abd13acfb",
              "IPY_MODEL_15a6fad93bdb44a5ad0fb2ae74a28ff9"
            ],
            "layout": "IPY_MODEL_184b8a10da6c4f3fb6dbbf02ba7e06b0"
          }
        },
        "390ecdd4084e42d88fd6fa0c9edfcecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eafe060389741ea81c988fc570f0fad",
            "placeholder": "​",
            "style": "IPY_MODEL_7c35b2e972c04601b01804f997bcf188",
            "value": "100%"
          }
        },
        "42aaeaaad8e24bcb98324243d16840c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db61befee504eacb1e40adbff3be8b9",
              "IPY_MODEL_728e62f8dfd143de8b39497664ac9d82",
              "IPY_MODEL_ac6ceca9a1d24074badcb9b1d14e749e"
            ],
            "layout": "IPY_MODEL_0345115c50ea437ba86c1e54d39472a5"
          }
        },
        "53d2fb40b2484067a0ea09aa3e611819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b98cc8fa4943519d9f0517ca9c2922": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ac058876f6343fe82fc0050fea08f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6db61befee504eacb1e40adbff3be8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45d099b4fe64553b33c53e8568e2110",
            "placeholder": "​",
            "style": "IPY_MODEL_9b3b5f80f1824db995f1550bb8e81a7d",
            "value": "Batches: 100%"
          }
        },
        "6f4bd829cc2c4d7b8378f2217f77f9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92c2988898146d4b8ebb5887d1cc654",
            "placeholder": "​",
            "style": "IPY_MODEL_c62150b0dec64aa8ac7060cc315761c9",
            "value": "Batches: 100%"
          }
        },
        "728e62f8dfd143de8b39497664ac9d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d738e93774384ffb9c1451385b858acf",
            "max": 2344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55b98cc8fa4943519d9f0517ca9c2922",
            "value": 2344
          }
        },
        "74c54fdcc87c49b5b7b72d2f9c3e6c22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c35b2e972c04601b01804f997bcf188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd1800a7c6a4c168c699eace3089e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb7398d7df024d84a768f1da1e94aeda",
            "max": 2344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5a7cd1157734115b01c5aa4fe24ac17",
            "value": 2344
          }
        },
        "8eafe060389741ea81c988fc570f0fad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3b5f80f1824db995f1550bb8e81a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b596319f5fd460a8c518b9bd927d262": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5140e4171e42629d313b3cd59f3756",
            "max": 75000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7b8bc651fcb41c8b89cb7338a5aa32f",
            "value": 75000
          }
        },
        "a01488b794fb4b23999c181c72fd5fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_390ecdd4084e42d88fd6fa0c9edfcecf",
              "IPY_MODEL_9b596319f5fd460a8c518b9bd927d262",
              "IPY_MODEL_1978eacbf6cd4e0388dede497e41bce8"
            ],
            "layout": "IPY_MODEL_ef47827ce7f841949db1d6b9cfb209c2"
          }
        },
        "a45d099b4fe64553b33c53e8568e2110": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90bce5c599244b1b8bbe12d2f2e4b39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac6ceca9a1d24074badcb9b1d14e749e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90bce5c599244b1b8bbe12d2f2e4b39",
            "placeholder": "​",
            "style": "IPY_MODEL_0cfc2d9de67b4ce6b6ae0b646a606b30",
            "value": " 2344/2344 [02:23&lt;00:00, 105.76it/s]"
          }
        },
        "b92c2988898146d4b8ebb5887d1cc654": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7398d7df024d84a768f1da1e94aeda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdf3bf15e7744e7832780d2e80f83dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c62150b0dec64aa8ac7060cc315761c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c778143adcbd4ee3b218825bca3748bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b8bc651fcb41c8b89cb7338a5aa32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc4ad365efd44cabae9b8bd69f364fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74c54fdcc87c49b5b7b72d2f9c3e6c22",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac058876f6343fe82fc0050fea08f32",
            "value": " 2344/2344 [02:23&lt;00:00, 74.90it/s]"
          }
        },
        "d738e93774384ffb9c1451385b858acf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e89fb341d44fbfa3d37201d014b39c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef47827ce7f841949db1d6b9cfb209c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a7cd1157734115b01c5aa4fe24ac17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb41578f13694ad18385185abd13acfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c7c0c4338240b2bad46e9c7173ab01",
            "max": 75000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53d2fb40b2484067a0ea09aa3e611819",
            "value": 75000
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
